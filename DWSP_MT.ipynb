{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1015285,
          "sourceType": "datasetVersion",
          "datasetId": 558095
        }
      ],
      "dockerImageVersionId": 30184,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "DWSP-MT",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/refercon/ipynb/blob/main/DWSP_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'bias-correction-ucl:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F558095%2F1015285%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240222%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240222T071839Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D58b1044f25a2afc6be7e47d7fd289a3e5c70e6e09390358596e3e81ba7d24b2ec0f019afb1f53a6ca201429041d723fef41597383b80215307f09aa5ec323baf7b91787230f41b4f3a85ee7cf5420d68c3727543de05ee1ca51139db69e43f8a9ee7aae508abffcc7583babe4d26132bbf2fcf88e4b24021fd6930011ec1b67bb2cb12129034d07f53dc9d6abd973138c698e9a91335be837470547a0ab93a2ec4a395dafb0f566fa0ddea725e1e1312e6c5af3a1869af25bb7ffb5edacab18780ead33a72d5af5bc0ff5584f7f50b8b9c1b644476618fbd2301a69b116e9950f205ea2ab0a93ca94c97e63f4e4f36884a9c77685b80e7a7ce5ad4b73437a0f9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW99RDAKrmXi",
        "outputId": "1767c018-ff4c-4933-db59-a39f6cd9f7ce"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bias-correction-ucl, 654062 bytes compressed\n",
            "[==================================================] 654062 bytes downloaded\n",
            "Downloaded and uncompressed: bias-correction-ucl\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset pre-processing"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-05-16T02:29:06.217001Z",
          "iopub.execute_input": "2022-05-16T02:29:06.217359Z",
          "iopub.status.idle": "2022-05-16T02:29:06.559973Z",
          "shell.execute_reply.started": "2022-05-16T02:29:06.21732Z",
          "shell.execute_reply": "2022-05-16T02:29:06.559168Z"
        },
        "id": "4bTfAXaSrmXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from functools import reduce\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv('../input/bias-correction-ucl/Bias_correction_ucl.csv')\n",
        "#df['Worker'] = 'NULL'\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.loc[:,['Date','LDAPS_Tmax_lapse','LDAPS_RHmax','LDAPS_CC2','LDAPS_WS','Solar radiation']]\n",
        "df.columns = ['Location','TEMP','Humidity','Cloud','Wind-speed','SR']\n",
        "data  = df.groupby('Location')\n",
        "data_limit_10 = list(data)[0:20]\n",
        "X = []\n",
        "for i in range(len(data_limit_10)):\n",
        "    location = 'L' + str(i + 1)\n",
        "    data_limit_10[i][1]['Location'] = location\n",
        "    X.append(data_limit_10)\n",
        "X2 = []\n",
        "for j in range(len(data_limit_10)):\n",
        "    X1 = X[0][j][1].reset_index(drop=True)\n",
        "    X1.columns = ['Location'+str(j+1),'TEMP'+str(j+1),\n",
        "                  'Humidity'+str(j+1),'Cloud'+str(j+1),'Wind-speed'+str(j+1),'SR'+str(j+1)]\n",
        "    X1.index = X1.index + 1\n",
        "    X1.insert(0, 'Worker', 'GD-W' + X1.index.astype(str))\n",
        "    X2.append(X1)\n",
        "pd.set_option('max_columns',10)\n",
        "pd.set_option('max_rows',10)\n",
        "GD = reduce(lambda left,right: pd.merge(left,right,how='outer',on=\"Worker\"), X2).fillna(method='pad')\n",
        "GD['Label'] = 1\n",
        "GD_TEMP = GD.filter(regex='Worker|TEMP')\n",
        "GD_HUM = GD.filter(regex='Worker|Humidity')\n",
        "GD_CLD = GD.filter(regex='Worker|Cloud')\n",
        "GD_CLD.iloc[:,1:21] *= 100\n",
        "GD_WSD = GD.filter(regex='Worker|Wind-speed')\n",
        "GD_WSD.iloc[:,1:21] *=  2\n",
        "GD_SR = GD.filter(regex='Worker|SR')\n",
        "GD_SR.iloc[:,1:21] /= 100 # (GD_SR.iloc[:,1:21] - GD_SR.iloc[:,1:21].mean()) / GD_SR.iloc[:,1:21].std() #normalization\n",
        "GD_TEMP.to_csv('gd.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:10.152522Z",
          "iopub.execute_input": "2024-01-03T14:16:10.152858Z",
          "iopub.status.idle": "2024-01-03T14:16:11.324927Z",
          "shell.execute_reply.started": "2024-01-03T14:16:10.152774Z",
          "shell.execute_reply": "2024-01-03T14:16:11.323861Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "s5oFdZ_WrmXo",
        "outputId": "b09d640b-4624-41d9-a3e6-f02028af8968"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OptionError",
          "evalue": "Pattern matched multiple keys",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8d47d221e185>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Worker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GD-W'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_columns'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_rows'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mGD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Worker\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# error: Signature of \"__doc__\" incompatible with supertype \"object\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_registered_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such keys(s): {repr(pat)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pattern matched multiple keys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOptionError\u001b[0m: Pattern matched multiple keys"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Building unknown dataset"
      ],
      "metadata": {
        "id": "gOcyKYPVrmXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80 workers(\"AT\"， “TPA”, \"Spammer\")\n",
        "# There are 10 time-steps in DPC, and DPC arranges 2 locations to workers in 1 time-step.\n",
        "# 20 “TPA” satisfied accuracy 100% in a specific typle of task.\n",
        "# 20 \"AT\" satisfied accuracy ？% in all tasks, but the accuracy is lower in a specific typle of task.\n",
        "# 40 other workers satisfied distribution randomly.\n",
        "# 20 “TPA” are generated by GD in a specific typle of task.For example,\n",
        "# A “TPA” worker submits true data in a typle of TEMP and false data in a typle of humidity, and etc.\n",
        "# 15 “TPA”  workers has a higher accuracy of single task.  5 workers has a higher accuracy of some tasks.\n",
        "# 20 \"AT\" workers has a lower accuracy of single task , but has a higer accuracy of single location.\n",
        "# 40 other workers: 30 workers satisfied accuracy 100% in a specific typle of task and not all of the time-steps.\n",
        "# 40 other workers: 10 workers satisfied accuracy 0 in all of the time-steps.\n",
        "\n",
        "# def font_color(val):\n",
        "#     print(val)\n",
        "#     color = 'green' if int(val) == 1 else 'red'\n",
        "#     return 'color: %s' % color\n",
        "\n",
        "# .sample(frac=1)\n",
        "# UNK_workers_TEMP = X3.filter(regex='Worker|TEMP').drop(X3.index.to_list(),axis = 0)\n",
        "TPA_TEMP = GD_TEMP.reset_index(drop=True).drop(GD_TEMP.tail(5).index).drop('Worker',axis=1)\n",
        "TPA_HUM = GD_HUM.reset_index(drop=True).drop(GD_HUM.tail(5).index).drop('Worker',axis=1)\n",
        "TPA_CLD = GD_CLD.reset_index(drop=True).drop(GD_CLD.tail(5).index).drop('Worker',axis=1)\n",
        "TPA_WSD = GD_WSD.reset_index(drop=True).drop(GD_WSD.tail(5).index).drop('Worker',axis=1)\n",
        "TPA_SR = GD_SR.reset_index(drop=True).drop(GD_SR.tail(5).index).drop('Worker',axis=1)\n",
        "\n",
        "TPA_TEMP.index = TPA_TEMP.index + 1\n",
        "TPA_TEMP.insert(0, 'Worker', 'UN-W' + TPA_TEMP.index.astype(str))\n",
        "TPA_TEMP.insert(21, 'Label', 0)\n",
        "TPA_TEMP.loc[0:3,'Label'] = 1\n",
        "TPA_TEMP.loc[16:20,'Label'] = 1\n",
        "TPA_TEMP.iloc[3:10,1:],TPA_TEMP.iloc[10:15,1:] = TPA_TEMP.iloc[3:10,1:] * 1.3,TPA_TEMP.iloc[10:15,1:] * 0.7\n",
        "\n",
        "TPA_HUM.index = TPA_HUM.index + 1\n",
        "TPA_HUM.insert(0, 'Worker', 'UN-W' + TPA_HUM.index.astype(str))\n",
        "TPA_HUM.insert(21, 'Label', 0)\n",
        "TPA_HUM.loc[4:6,'Label'] = 1\n",
        "TPA_HUM.loc[16:20,'Label'] = 1\n",
        "TPA_HUM.iloc[0:3,1:],TPA_HUM.iloc[6:15,1:] = TPA_HUM.iloc[0:3,1:] * 1.2,TPA_HUM.iloc[6:15,1:] * 0.8\n",
        "\n",
        "TPA_CLD.index = TPA_CLD.index + 1\n",
        "TPA_CLD.insert(0, 'Worker', 'UN-W' + TPA_CLD.index.astype(str))\n",
        "TPA_CLD.insert(21, 'Label', 0)\n",
        "TPA_CLD.loc[7:9,'Label'] = 1\n",
        "TPA_CLD.loc[16:20,'Label'] = 1\n",
        "TPA_CLD.iloc[0:6,1:],TPA_CLD.iloc[9:15,1:] = TPA_CLD.iloc[0:6,1:] / 3,TPA_CLD.iloc[9:15,1:] / 2\n",
        "\n",
        "TPA_WSD.index = TPA_WSD.index + 1\n",
        "TPA_WSD.insert(0, 'Worker', 'UN-W' + TPA_WSD.index.astype(str))\n",
        "TPA_WSD.insert(21, 'Label', 0)\n",
        "TPA_WSD.loc[10:12,'Label'] = 1\n",
        "TPA_WSD.loc[16:20,'Label'] = 1\n",
        "TPA_WSD.iloc[0:9,1:],TPA_WSD.iloc[12:15,1:] = TPA_WSD.iloc[0:9,1:] * 2,TPA_WSD.iloc[12:15,1:] / 2\n",
        "\n",
        "TPA_SR.index = TPA_SR.index + 1\n",
        "TPA_SR.insert(0, 'Worker', 'UN-W' + TPA_SR.index.astype(str))\n",
        "TPA_SR.insert(21, 'Label', 0)\n",
        "TPA_SR.loc[13:15,'Label'] = 1\n",
        "TPA_SR.iloc[0:12,1:],TPA_SR.iloc[15:20,1:] = TPA_SR.iloc[0:12,1:] * 1.2 ,TPA_SR.iloc[15:20,1:] / 1.1\n",
        "\n",
        "AT_TEMP = TPA_TEMP.append(GD_TEMP.iloc[:20,1:])\n",
        "AT_TEMP = AT_TEMP.reset_index(drop=True)\n",
        "AT_TEMP.index = AT_TEMP.index + 1\n",
        "AT_TEMP.loc[21:40,'Worker'] = 'UN-W' + AT_TEMP.loc[21:40,'Worker'].index.astype(str)\n",
        "AT_TEMP.loc[21:40,'Label'] = 2\n",
        "AT_TEMP.iloc[20:40,1:6] = AT_TEMP.iloc[20:40,1:6] * 1.3\n",
        "\n",
        "AT_HUM = TPA_HUM.append(GD_HUM.iloc[:20,1:])\n",
        "AT_HUM = AT_HUM.reset_index(drop=True)\n",
        "AT_HUM.index = AT_HUM.index + 1\n",
        "AT_HUM.loc[21:40,'Worker'] = 'UN-W' + AT_TEMP.loc[21:40,'Worker'].index.astype(str)\n",
        "AT_HUM.loc[21:40,'Label'] = 2\n",
        "AT_HUM.iloc[20:40,1:6],AT_HUM.iloc[20:40,19:21] = AT_HUM.iloc[20:40,1:6] * 1.2,AT_HUM.iloc[20:40,1:6] * .8\n",
        "\n",
        "AT_CLD = TPA_CLD.append(GD_CLD.iloc[:20,1:])\n",
        "AT_CLD = AT_CLD.reset_index(drop=True)\n",
        "AT_CLD.index = AT_CLD.index + 1\n",
        "AT_CLD.loc[21:40,'Worker'] = 'UN-W' + AT_CLD.loc[21:40,'Worker'].index.astype(str)\n",
        "AT_CLD.loc[21:40,'Label'] = 2\n",
        "AT_CLD.iloc[20:40,1:6] = AT_CLD.iloc[20:40,1:6] / 2\n",
        "\n",
        "AT_WSD = TPA_WSD.append(GD_WSD.iloc[:20,1:])\n",
        "AT_WSD = AT_WSD.reset_index(drop=True)\n",
        "AT_WSD.index = AT_WSD.index + 1\n",
        "AT_WSD.loc[21:40,'Worker'] = 'UN-W' + AT_WSD.loc[21:40,'Worker'].index.astype(str)\n",
        "AT_WSD.loc[21:40,'Label'] = 2\n",
        "AT_WSD.iloc[20:40,1:6],AT_WSD.iloc[20:40,19:21] = AT_WSD.iloc[20:40,1:6] * 2,AT_WSD.iloc[20:40,1:6] / 2\n",
        "\n",
        "AT_SR = TPA_SR.append(GD_SR.iloc[:20,1:])\n",
        "AT_SR = AT_SR.reset_index(drop=True)\n",
        "AT_SR.index = AT_SR.index + 1\n",
        "AT_SR.loc[21:40,'Worker'] = 'UN-W' + AT_SR.loc[21:40,'Worker'].index.astype(str)\n",
        "AT_SR.loc[21:40,'Label'] = 2\n",
        "AT_SR.iloc[20:40,1:6],AT_SR.iloc[20:40,19:21] = AT_SR.iloc[20:40,1:6] * 2,AT_SR.iloc[20:40,1:6] / 2\n",
        "\n",
        "OW_TEMP = AT_TEMP.append(AT_TEMP,ignore_index=True)\n",
        "OW_TEMP.loc[40:,'Worker'] = 'UN-W' + (OW_TEMP.loc[40:,'Worker'].index +1).astype(str)\n",
        "OW_TEMP.loc[40:,'Label'] = 0\n",
        "OW_TEMP.iloc[40:70,1:11] = OW_TEMP.iloc[40:70,1:11] * 1.3\n",
        "OW_TEMP.iloc[70:80,1:21] = OW_TEMP.iloc[70:80,1:21] * 0.7\n",
        "\n",
        "OW_HUM = AT_HUM.append(AT_HUM,ignore_index=True)\n",
        "OW_HUM.loc[40:,'Worker'] = 'UN-W' + (OW_HUM.loc[40:,'Worker'].index +1).astype(str)\n",
        "OW_HUM.loc[40:,'Label'] = 0\n",
        "OW_HUM.iloc[40:70,1:11] = OW_HUM.iloc[40:70,1:11] * 1.3\n",
        "OW_HUM.iloc[70:80,1:21] = OW_HUM.iloc[70:80,1:21] * 0.7\n",
        "\n",
        "OW_CLD = AT_CLD.append(AT_CLD,ignore_index=True)\n",
        "OW_CLD.loc[40:,'Worker'] = 'UN-W' + (OW_CLD.loc[40:,'Worker'].index +1).astype(str)\n",
        "OW_CLD.loc[40:,'Label'] = 0\n",
        "OW_CLD.iloc[40:70,10:21] = OW_CLD.iloc[40:70,10:21] / 3\n",
        "OW_CLD.iloc[70:80,1:21] = OW_CLD.iloc[70:80,1:21] / 2\n",
        "\n",
        "OW_WSD = AT_WSD.append(AT_WSD,ignore_index=True)\n",
        "OW_WSD.loc[40:,'Worker'] = 'UN-W' + (OW_WSD.loc[40:,'Worker'].index +1).astype(str)\n",
        "OW_WSD.loc[40:,'Label'] = 0\n",
        "OW_WSD.iloc[40:70,1:11] = OW_WSD.iloc[40:70,1:11] * 2\n",
        "OW_WSD.iloc[70:80,1:21] = OW_WSD.iloc[70:80,1:21] / 2\n",
        "\n",
        "OW_SR = AT_SR.append(AT_SR,ignore_index=True)\n",
        "OW_SR.loc[40:,'Worker'] = 'UN-W' + (OW_SR.loc[40:,'Worker'].index +1).astype(str)\n",
        "OW_SR.loc[40:,'Label'] = 0\n",
        "OW_SR.iloc[40:70,10:21] = OW_SR.iloc[40:70,10:21] * 2\n",
        "OW_SR.iloc[70:80,1:21] = OW_SR.iloc[70:80,1:21] / 2\n",
        "\n",
        "pd.set_option('max_columns',10)\n",
        "pd.set_option('max_rows',100)\n",
        "OW_TEMP\n",
        "OW_HUM\n",
        "OW_CLD\n",
        "OW_WSD\n",
        "OW_SR"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:11.326525Z",
          "iopub.execute_input": "2024-01-03T14:16:11.326768Z",
          "iopub.status.idle": "2024-01-03T14:16:11.577698Z",
          "shell.execute_reply.started": "2024-01-03T14:16:11.32674Z",
          "shell.execute_reply": "2024-01-03T14:16:11.577213Z"
        },
        "trusted": true,
        "id": "JY8RdUtPrmXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data classfication**"
      ],
      "metadata": {
        "id": "_KNUvlJhrmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "warnings.filterwarnings('ignore')\n",
        "GD_TEMP_fit = GD_TEMP.drop('Worker',axis=1)\n",
        "UN_TEMP_fit = OW_TEMP.drop(['Worker','Label'],axis=1)\n",
        "\n",
        "GD_HUM_fit = GD_HUM.drop('Worker',axis=1)\n",
        "UN_HUM_fit = OW_HUM.drop(['Worker','Label'],axis=1)\n",
        "\n",
        "GD_CLD_fit = GD_CLD.drop('Worker',axis=1)\n",
        "UN_CLD_fit = OW_CLD.drop(['Worker','Label'],axis=1)\n",
        "\n",
        "GD_WSD_fit = GD_WSD.drop('Worker',axis=1)\n",
        "UN_WSD_fit = OW_WSD.drop(['Worker','Label'],axis=1)\n",
        "\n",
        "GD_SR_fit = GD_SR.drop('Worker',axis=1)\n",
        "UN_SR_fit = OW_SR.drop(['Worker','Label'],axis=1)\n",
        "\n",
        "pd.set_option('max_columns',20)\n",
        "pd.set_option('max_rows',100)\n",
        "\n",
        "# nus = [0.1,0.01, 0.02, 0.1, 1]\n",
        "# gammas = [0.1,0.01, 0.02, 0.1, 1]\n",
        "# tuned_parameters = {'kernel' : ['rbf'], 'gamma' : gammas, 'nu': nus}\n",
        "# scores = ['accuracy', 'f1-score']\n",
        "# for score in scores:\n",
        "#     estimator = GridSearchCV(svm.OneClassSVM(), tuned_parameters, cv=10,\n",
        "#                            scoring='f1' , return_train_score=True)\n",
        "\n",
        "#     estimator.fit(GD_TEMP_fit.iloc[0:19,0:2],GD.iloc[0:19,-1])\n",
        "#     y_predict = estimator.predict(UN_TEMP_fit.iloc[0:19,0:2])\n",
        "# #     print(y_predict)\n",
        "#     resultDf = pd.DataFrame(estimator.cv_results_)\n",
        "# #     print(resultDf[[\"mean_test_score\", \"std_test_score\", \"params\"]].sort_values(by=[\"mean_test_score\"],\n",
        "# #                                                                                 ascending=False).head())\n",
        "#     print(estimator.best_params_)\n",
        "# resultDf\n",
        "search_params = pd.DataFrame({'nus':[0],'GD_ACC':[0],'GD_F1score':[0],'Test_ACC':[0],'Test_F1score':[0]})\n",
        "nus = 0\n",
        "i = 0\n",
        "while nus <= 0.99:\n",
        "    nus += 0.01\n",
        "    i += 1\n",
        "    estimator= svm.OneClassSVM(nu=nus, kernel=\"rbf\", gamma=0.01)\n",
        "#     for t in range(20):\n",
        "#         if t % 2 == 0:\n",
        "    GD_temp_shuffle = GD_TEMP_fit.iloc[:,0:2].sample(frac=1)\n",
        "    UN_temp_shuffle = UN_TEMP_fit.iloc[:,0:2]\n",
        "    estimator.fit(GD_temp_shuffle)\n",
        "    y_pred_temp_gd = estimator.predict(GD_temp_shuffle)\n",
        "    y_pred_temp = estimator.predict(UN_temp_shuffle)\n",
        "#     TEMP = OW_TEMP.loc[:,['Worker','TEMP'+str(t + 1),'TEMP'+str(t + 2)]]\n",
        "#     predict_TEMP.append(TEMP[y_pred_temp==1])\n",
        "    for j in range(len(OW_TEMP.loc[0:19,'Label'])):\n",
        "        if OW_TEMP.loc[0:19,'Label'][j] != 1:\n",
        "            OW_TEMP.loc[0:19,'Label'][j] = -1\n",
        "    search_params.loc[i] = [nus,accuracy_score(GD.loc[0:19,'Label'],y_pred_temp_gd[0:20]),\n",
        "                            f1_score(GD.loc[0:19,'Label'],y_pred_temp_gd[0:20]),\n",
        "                            accuracy_score(OW_TEMP.loc[0:19,'Label'],y_pred_temp[0:20]),\n",
        "                            f1_score(OW_TEMP.loc[0:19,'Label'],y_pred_temp[0:20])]\n",
        "search_params.drop([0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:11.578837Z",
          "iopub.execute_input": "2024-01-03T14:16:11.579159Z",
          "iopub.status.idle": "2024-01-03T14:16:12.720663Z",
          "shell.execute_reply.started": "2024-01-03T14:16:11.579129Z",
          "shell.execute_reply": "2024-01-03T14:16:12.719957Z"
        },
        "trusted": true,
        "id": "QYtJaT8rrmXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-26T13:36:47.777572Z",
          "iopub.execute_input": "2022-05-26T13:36:47.77854Z",
          "iopub.status.idle": "2022-05-26T13:36:48.406779Z",
          "shell.execute_reply.started": "2022-05-26T13:36:47.778496Z",
          "shell.execute_reply": "2022-05-26T13:36:48.405867Z"
        },
        "id": "dlIyC0yWrmXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "##### from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "import warnings\n",
        "import matplotlib.pyplot  as plt\n",
        "from IPython.display import display\n",
        "warnings.filterwarnings('ignore')\n",
        "vars()['GT_fit'] = [GD_TEMP.drop('Worker',axis=1),GD_HUM.drop('Worker',axis=1),GD_CLD.drop('Worker',axis=1),GD_WSD.drop('Worker',axis=1),\n",
        "                    GD_SR.drop('Worker',axis=1)]\n",
        "vars()['UN_fit'] = [OW_TEMP.drop(['Worker','Label'],axis=1),OW_HUM.drop(['Worker','Label'],axis=1),\n",
        "                    OW_CLD.drop(['Worker','Label'],axis=1),OW_WSD.drop(['Worker','Label'],axis=1),\n",
        "                    OW_SR.drop(['Worker','Label'],axis=1)]\n",
        "vars()['reliable'] = [[],[],[],[],[]]\n",
        "vars()['unreliable'] = [[],[],[],[],[]]\n",
        "task = ['TEMP','Humidity','Cloud','Wind-speed','SR']\n",
        "vars()['ACC'] = [pd.DataFrame({'Task':[0],'Cycle':[0],'ACC':[0],'F1-score':[0]}),\n",
        "                 pd.DataFrame({'Task':[0],'Cycle':[0],'ACC':[0],'F1-score':[0]}),\n",
        "                 pd.DataFrame({'Task':[0],'Cycle':[0],'ACC':[0],'F1-score':[0]}),\n",
        "                 pd.DataFrame({'Task':[0],'Cycle':[0],'ACC':[0],'F1-score':[0]}),\n",
        "                 pd.DataFrame({'Task':[0],'Cycle':[0],'ACC':[0],'F1-score':[0]})]\n",
        "\n",
        "vars()['OW'] = [OW_TEMP,OW_HUM,OW_CLD,OW_WSD,OW_SR]\n",
        "estimator= svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.01)\n",
        "for f in range(len(vars()['reliable'])):\n",
        "    for t in range(20):\n",
        "        if t % 2 == 0:\n",
        "            estimator.fit(GT_fit[f].iloc[:,t:t+2])\n",
        "            y_pred_temp = estimator.predict(UN_fit[f].iloc[:,t:t + 2])\n",
        "            reliable[f].append(OW[f].loc[:,['Worker',task[f]+str(t + 1),task[f]+str(t + 2)]][y_pred_temp==1])\n",
        "            unreliable[f].append(OW[f].loc[:,['Worker',task[f]+str(t + 1),task[f]+str(t + 2)]][y_pred_temp==-1])#-1 unlabelled..\n",
        "            for i in range(len(OW[f].loc[0:19,'Label'])):\n",
        "                if OW[f].loc[0:19,'Label'][i] != 1:\n",
        "                    OW[f].loc[0:19,'Label'][i] = -1\n",
        "            ACC[f].loc[int(t/2)] = [task[f],'t'+str(int(t/2 + 1)),accuracy_score(OW[f].loc[0:19,'Label'],y_pred_temp[0:20]),\n",
        "                                    f1_score(OW[f].loc[0:19,'Label'],y_pred_temp[0:20])]\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(\"程序执行时间：\", execution_time, \"秒\")\n",
        "\n",
        "\n",
        "pd.set_option('max_columns',20)\n",
        "pd.set_option('max_rows',20)\n",
        "\n",
        "ACC[0].merge(ACC[1].merge(ACC[2].merge(ACC[3].merge(ACC[4],on=\"Cycle\"),on=\"Cycle\"),on=\"Cycle\"),on=\"Cycle\")\n",
        "\n",
        "# unreliable_all = []\n",
        "# for i in range(len(vars()['unreliable'])):\n",
        "#     for j in range(10):\n",
        "#         unreliable_all.append(unreliable[i][j])\n",
        "\n",
        "# unreliable_all = reduce(lambda left,right: pd.merge(left,right,how='outer',on=\"Worker\"),unreliable_all)\n",
        "# unreliable_all\n",
        "\n",
        "#分类效果图"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:12.722711Z",
          "iopub.execute_input": "2024-01-03T14:16:12.723286Z",
          "iopub.status.idle": "2024-01-03T14:16:13.303503Z",
          "shell.execute_reply.started": "2024-01-03T14:16:12.723161Z",
          "shell.execute_reply": "2024-01-03T14:16:13.302205Z"
        },
        "trusted": true,
        "id": "3KtOYIrFrmXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "7GCgul6hrmXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the process of training and predicting.\n",
        "plt.figure(figsize = (30,4))\n",
        "size = 14\n",
        "plt.subplot(151) #Temperature\n",
        "time_step1 = 0\n",
        "time_step2 = 2\n",
        "lam=0.01\n",
        "estimator= svm.OneClassSVM(nu=lam, kernel=\"rbf\", gamma=0.01)\n",
        "\n",
        "estimator.fit(GT_fit[0].iloc[:,time_step1:time_step2])\n",
        "predict_0 = estimator.predict(UN_fit[0].iloc[:,time_step1:time_step2])\n",
        "reliable_pre = UN_fit[0].iloc[:,time_step1:time_step2][predict_0==1]\n",
        "unreliable_pre = UN_fit[0].iloc[:,time_step1:time_step2][predict_0==-1]\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(0, 70, 50), np.linspace(0, 70, 50))\n",
        "Z = estimator.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 10), cmap=plt.cm.Blues)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=1, colors='red')\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
        "\n",
        "a = plt.scatter(GT_fit[0].iloc[:,time_step1:time_step1+1], GT_fit[0].iloc[:,time_step1+1:time_step2], c='white', s=60, edgecolors='k', marker='o')\n",
        "b = plt.scatter(reliable_pre.iloc[:,0:1], reliable_pre.iloc[:,1:2], c='#D00000', s=60,edgecolors='k', marker='o')\n",
        "c = plt.scatter(unreliable_pre.iloc[:,0:1], unreliable_pre.iloc[:,1:2],  c='#FFBA08', edgecolor='k', s=60, marker='x')\n",
        "plt.axis('tight')\n",
        "plt.xlim((10, 55))\n",
        "plt.ylim((10, 55))\n",
        "plt.xticks(size=size)\n",
        "plt.yticks(size=size)\n",
        "plt.text(15,50, f'$\\lambda={lam}$',fontsize=size)\n",
        "plt.legend([a, b, c],[ \"Ground truth\",\"Reliable data\", \"Unreliable data\"],loc=\"lower right\", prop={'size': size})\n",
        "# plt.xlabel('X1',fontsize=15)\n",
        "# plt.ylabel('X2',fontsize=15)\n",
        "# plt.grid(linestyle=\":\")\n",
        "\n",
        "plt.subplot(152)#Humidity\n",
        "estimator.fit(GT_fit[1].iloc[:,time_step1:time_step2])\n",
        "predict_1 = estimator.predict(UN_fit[1].iloc[:,time_step1:time_step2])\n",
        "reliable_pre = UN_fit[1].iloc[:,time_step1:time_step2][predict_1==1]\n",
        "unreliable_pre = UN_fit[1].iloc[:,time_step1:time_step2][predict_1==-1]\n",
        "xx, yy = np.meshgrid(np.linspace(0, 160, 50), np.linspace(0, 160, 50))\n",
        "Z = estimator.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 15), cmap=plt.cm.Blues)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=1, colors='red')\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
        "\n",
        "a = plt.scatter(GT_fit[1].iloc[:,time_step1:time_step1+1], GT_fit[1].iloc[:,time_step1+1:time_step2], c='white', s=60, edgecolors='k', marker='o')\n",
        "b = plt.scatter(reliable_pre.iloc[:,0:1], reliable_pre.iloc[:,1:2], c='#D00000', s=60,edgecolors='k', marker='o')\n",
        "c = plt.scatter(unreliable_pre.iloc[:,0:1], unreliable_pre.iloc[:,1:2],  c='#FFBA08', edgecolor='k', s=60, marker='x')\n",
        "plt.axis('tight')\n",
        "plt.xlim((50, 160))\n",
        "plt.ylim((50, 160))\n",
        "plt.xticks(size=size)\n",
        "plt.yticks(size=size)\n",
        "plt.text(65,145, f'$\\lambda={lam}$',fontsize=size)\n",
        "plt.legend([a, b, c],[ \"Ground truth\",\"Reliable data\", \"Unreliable data\"],loc=\"lower right\", prop={'size': size})\n",
        "# plt.xlabel('X1',fontsize=15)\n",
        "# plt.ylabel('X2',fontsize=15)\n",
        "# plt.grid(linestyle=\":\")\n",
        "\n",
        "plt.subplot(153)#Cloud\n",
        "estimator.fit(GT_fit[2].iloc[:,time_step1:time_step2])\n",
        "predict_2 = estimator.predict(UN_fit[2].iloc[:,time_step1:time_step2])\n",
        "reliable_pre = UN_fit[2].iloc[:,time_step1:time_step2][predict_2==1]\n",
        "unreliable_pre = UN_fit[2].iloc[:,time_step1:time_step2][predict_2==-1]\n",
        "xx, yy = np.meshgrid(np.linspace(0, 120, 50), np.linspace(0, 120, 50))\n",
        "Z = estimator.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 15), cmap=plt.cm.Blues)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=1, colors='red')\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
        "a = plt.scatter(GT_fit[2].iloc[:,time_step1:time_step1+1], GT_fit[2].iloc[:,time_step1+1:time_step2], c='white', s=60, edgecolors='k', marker='o')\n",
        "b = plt.scatter(reliable_pre.iloc[:,0:1], reliable_pre.iloc[:,1:2], c='#D00000', s=60,edgecolors='k', marker='o')\n",
        "c = plt.scatter(unreliable_pre.iloc[:,0:1], unreliable_pre.iloc[:,1:2],  c='#FFBA08', edgecolor='k', s=60, marker='x')\n",
        "plt.axis('tight')\n",
        "plt.text(5,105, f'$\\lambda={lam}$',fontsize=size)\n",
        "plt.xlim((0, 60))\n",
        "plt.ylim((10, 120))\n",
        "plt.xticks(size=size)\n",
        "plt.yticks(size=size)\n",
        "plt.legend([a, b, c],[ \"Ground truth\",\"Reliable data\", \"Unreliable data\"],loc=\"lower right\", prop={'size': size})\n",
        "# plt.xlabel('X1',fontsize=15)\n",
        "# plt.ylabel('X2',fontsize=15)\n",
        "# plt.grid(linestyle=\":\")\n",
        "\n",
        "plt.subplot(154)#Wind-speed\n",
        "estimator.fit(GT_fit[3].iloc[:,time_step1:time_step2])\n",
        "predict_3 = estimator.predict(UN_fit[3].iloc[:,time_step1:time_step2])\n",
        "reliable_pre = UN_fit[3].iloc[:,time_step1:time_step2][predict_3==1]\n",
        "unreliable_pre = UN_fit[3].iloc[:,time_step1:time_step2][predict_3==-1]\n",
        "xx, yy = np.meshgrid(np.linspace(-5, 120, 50), np.linspace(-5, 120, 50))\n",
        "Z = estimator.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 15), cmap=plt.cm.Blues)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=1, colors='red')\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
        "a = plt.scatter(GT_fit[3].iloc[:,time_step1:time_step1+1], GT_fit[3].iloc[:,time_step1+1:time_step2], c='white', s=60, edgecolors='k', marker='o')\n",
        "b = plt.scatter(reliable_pre.iloc[:,0:1], reliable_pre.iloc[:,1:2], c='#D00000', s=60,edgecolors='k', marker='o')\n",
        "c = plt.scatter(unreliable_pre.iloc[:,0:1], unreliable_pre.iloc[:,1:2],  c='#FFBA08', edgecolor='k', s=60, marker='x')\n",
        "plt.text(5,105,  f'$\\lambda={lam}$',fontsize=14)\n",
        "plt.axis('tight')\n",
        "plt.xlim((-5, 60))\n",
        "plt.ylim((-5, 120))\n",
        "plt.xticks(size=size)\n",
        "plt.yticks(size=size)\n",
        "plt.legend([a, b, c],[ \"Ground truth\",\"Reliable data\", \"Unreliable data\"],loc=\"lower right\", prop={'size': size})\n",
        "# plt.xlabel('X1',fontsize=15)\n",
        "# plt.ylabel('X2',fontsize=15)\n",
        "# plt.grid(linestyle=\":\")\n",
        "\n",
        "plt.subplot(155)#Solar-radiation\n",
        "estimator.fit(GT_fit[4].iloc[:,time_step1:time_step2])\n",
        "predict_4 = estimator.predict(UN_fit[4].iloc[:,0:2])\n",
        "reliable_pre = UN_fit[4].iloc[:,time_step1:time_step2][predict_4==1]\n",
        "unreliable_pre = UN_fit[4].iloc[:,time_step1:time_step2][predict_4==-1]\n",
        "xx, yy = np.meshgrid(np.linspace(-5, 80, 50), np.linspace(-5, 80, 50))\n",
        "Z = estimator.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues)\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 10), cmap=plt.cm.Blues)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=1, colors='red')\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
        "a = plt.scatter(GT_fit[4].iloc[:,time_step1:time_step1+1], GT_fit[4].iloc[:,time_step1+1:time_step2], c='white', s=60, edgecolors='k', marker='o')\n",
        "b = plt.scatter(reliable_pre.iloc[:,0:1], reliable_pre.iloc[:,1:2], c='#D00000', s=60,edgecolors='k', marker='o')\n",
        "c = plt.scatter(unreliable_pre.iloc[:,0:1], unreliable_pre.iloc[:,1:2], c='#FFBA08',edgecolor='k', s=60, marker='x')\n",
        "plt.text(45,75, f'$\\lambda={lam}$',fontsize=size)\n",
        "plt.axis('tight')\n",
        "plt.xlim((40, 80))\n",
        "plt.ylim((40, 80))\n",
        "plt.xticks(size=size)\n",
        "plt.yticks(size=size)\n",
        "plt.legend([a, b, c],[ \"Ground truth\",\"Reliable data\", \"Unreliable data\"],loc=\"lower right\", prop={'size': size})\n",
        "# plt.xlabel('X1',fontsize=15)\n",
        "# plt.ylabel('X2',fontsize=15)\n",
        "# plt.grid(linestyle=\":\")\n",
        "plt.savefig(f'{lam}.svg',dpi=600,bbox_inches = 'tight')\n",
        "plt.show()\n",
        "GT_fit[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:13.304921Z",
          "iopub.execute_input": "2024-01-03T14:16:13.305361Z",
          "iopub.status.idle": "2024-01-03T14:16:15.698468Z",
          "shell.execute_reply.started": "2024-01-03T14:16:13.305328Z",
          "shell.execute_reply": "2024-01-03T14:16:15.697781Z"
        },
        "trusted": true,
        "id": "xeD0CYqLrmXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font1 = {\n",
        "'weight' : 'normal',\n",
        "'size' : 20,\n",
        "}\n",
        "fontsize = 20\n",
        "size = 14\n",
        "plt.figure(figsize = (30,10))\n",
        "plt.subplots_adjust(left=None,bottom=None,right=None,top=None,wspace=0.3)\n",
        "plt.subplot(251)\n",
        "original_data = plt.scatter(UN_fit[0].iloc[:,0:1],UN_fit[0].iloc[:,1:2],marker=\".\",facecolor='#699BCD',s=120)\n",
        "abnomal_data = plt.scatter(UN_fit[0].iloc[:,0:1][predict_0==-1],UN_fit[0].iloc[:,1:2][predict_0==-1],\n",
        "                           marker=\"o\",facecolor='none',edgecolors='orange',s=80)\n",
        "plt.legend((abnomal_data,original_data),('Unreliable data',\n",
        "                                         'Reliable data'),prop=font1)\n",
        "plt.grid(linestyle=':')\n",
        "plt.tick_params(labelsize=fontsize)\n",
        "\n",
        "plt.subplot(252)\n",
        "original_data = plt.scatter(UN_fit[1].iloc[:,0:1],UN_fit[1].iloc[:,1:2],marker=\".\",facecolor='#699BCD',s=120)\n",
        "abnomal_data = plt.scatter(UN_fit[1].iloc[:,0:1][predict_1==-1],UN_fit[1].iloc[:,1:2][predict_1==-1],\n",
        "                           marker=\"o\",facecolor='none',edgecolors='orange',s=80)\n",
        "plt.legend((abnomal_data,original_data),('Unreliable data',\n",
        "                                         'Reliable data'),prop=font1)\n",
        "plt.grid(linestyle=':')\n",
        "plt.tick_params(labelsize=fontsize)\n",
        "\n",
        "plt.subplot(253)\n",
        "original_data = plt.scatter(UN_fit[2].iloc[:,0:1],UN_fit[2].iloc[:,1:2],marker=\".\",facecolor='#699BCD',s=120)\n",
        "abnomal_data = plt.scatter(UN_fit[2].iloc[:,0:1][predict_2==-1],UN_fit[2].iloc[:,1:2][predict_2==-1],\n",
        "                           marker=\"o\",facecolor='none',edgecolors='orange',s=80)\n",
        "plt.legend((abnomal_data,original_data),('Unreliable data',\n",
        "                                         'Reliable data'),prop=font1,loc=\"lower right\")\n",
        "plt.grid(linestyle=':')\n",
        "plt.tick_params(labelsize=fontsize)\n",
        "\n",
        "plt.subplot(254)#Postive data distribution\n",
        "original_data = plt.scatter(UN_fit[3].iloc[:,0:1],UN_fit[3].iloc[:,1:2],marker=\".\",facecolor='#699BCD',s=120)\n",
        "abnomal_data = plt.scatter(UN_fit[3].iloc[:,0:1][predict_3==-1],UN_fit[3].iloc[:,1:2][predict_3==-1],\n",
        "                           marker=\"o\",facecolor='none',edgecolors='orange',s=80)\n",
        "\n",
        "plt.legend((abnomal_data,original_data),('Unreliable data',\n",
        "                                         'Reliable data'),prop=font1,loc=\"upper left\")\n",
        "plt.grid(linestyle=':')\n",
        "plt.tick_params(labelsize=fontsize)\n",
        "\n",
        "plt.subplot(255)#Postive data distribution\n",
        "original_data = plt.scatter(UN_fit[4].iloc[:,0:1],UN_fit[4].iloc[:,1:2],marker=\".\",facecolor='#699BCD',s=120)\n",
        "abnomal_data = plt.scatter(UN_fit[4].iloc[:,0:1][predict_4==-1],UN_fit[4].iloc[:,1:2][predict_4==-1],\n",
        "                           marker=\"o\",facecolor='none',edgecolors='orange',s=80)\n",
        "\n",
        "plt.legend((abnomal_data,original_data),('Unreliable data',\n",
        "                                         'Reliable data'),prop=font1)\n",
        "plt.grid(linestyle=':')\n",
        "plt.tick_params(labelsize=fontsize)\n",
        "\n",
        "plt.savefig('1-1.svg',dpi=600,bbox_inches = 'tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:15.701419Z",
          "iopub.execute_input": "2024-01-03T14:16:15.701724Z",
          "iopub.status.idle": "2024-01-03T14:16:16.856151Z",
          "shell.execute_reply.started": "2024-01-03T14:16:15.701691Z",
          "shell.execute_reply": "2024-01-03T14:16:16.855619Z"
        },
        "trusted": true,
        "id": "mSM4asNVrmXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn as skl\n",
        "import matplotlib.pyplot as plt\n",
        "from cycler import cycler\n",
        "plt.figure(figsize = (30,4))\n",
        "plt.rc('axes', prop_cycle=(cycler('color', ['#F51420','#C06000','#777E00','#008B00', '#008EA0']) +\n",
        "                           cycler('linestyle', ['-', '--', ':', '-.', '-.'])))\n",
        "\n",
        "def plot_roc(t,y_test, y_pred,subsize,label_postion=\"lower right\"):\n",
        "    fpr, tpr, thresholds = skl.metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
        "    print(fpr,',', tpr)\n",
        "\n",
        "    roc_auc = skl.metrics.auc(fpr, tpr)\n",
        "    lw = 2\n",
        "    plt.subplot(1,5,subsize)\n",
        "    plt.plot(fpr, tpr, lw=lw, label=t+' ROC (AUC={0:.2f})'.format(roc_auc))\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.ylabel('True positive rate')\n",
        "    plt.legend(loc=label_postion)\n",
        "    plt.grid(linestyle=\":\")\n",
        "\n",
        "plot_roc('TEMP',OW[0].loc[0:19,'Label'], predict_0[0:20],1)\n",
        "plot_roc('HUM',OW[1].loc[0:19,'Label'], predict_1[0:20],1)\n",
        "plot_roc('CLD',OW[2].loc[0:19,'Label'], predict_2[0:20],1)\n",
        "plot_roc('WSD',OW[3].loc[0:19,'Label'], predict_3[0:20],1)\n",
        "plot_roc('SR',OW[4].loc[0:19,'Label'], predict_4[0:20],1)\n",
        "plt.savefig('2.svg',dpi=600,bbox_inches = 'tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:16.857135Z",
          "iopub.execute_input": "2024-01-03T14:16:16.858704Z",
          "iopub.status.idle": "2024-01-03T14:16:17.188085Z",
          "shell.execute_reply.started": "2024-01-03T14:16:16.85867Z",
          "shell.execute_reply": "2024-01-03T14:16:17.187145Z"
        },
        "trusted": true,
        "id": "4KkF5NyyrmXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Calculate trust according to the reliable data"
      ],
      "metadata": {
        "id": "C3e96aGjrmXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "pd.set_option('max_columns',10)\n",
        "pd.set_option('max_rows',10)\n",
        "vars()['reliable'] = [reliable[0],reliable[1],reliable[2],reliable[3],reliable[4]]\n",
        "task = ['TEMP','Humidity','Cloud','Wind-speed','SR']\n",
        "for i in range(len(vars()['reliable'])):\n",
        "    vars()['reliable_trust_'+str(i)] = reduce(lambda left,right: pd.merge(left,right,how='outer',on=\"Worker\"), reliable[i]).fillna(0)\n",
        "    vars()['reliable_trust_'+str(i)]['Correct'] = 0.00\n",
        "    for j in range(len( vars()['reliable_trust_'+str(i)])):\n",
        "        m = 0\n",
        "        for k in range(20):\n",
        "            if  vars()['reliable_trust_'+str(i)][task[i]+str(k+1)][j] > 0:\n",
        "                m = m + 1\n",
        "        vars()['reliable_trust_'+str(i)]['Correct'][j] = m / 20\n",
        "execution_time = end_time - start_time\n",
        "print(\"程序执行时间：\", execution_time, \"秒\")\n",
        "reliable_trust_0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:17.189483Z",
          "iopub.execute_input": "2024-01-03T14:16:17.189714Z",
          "iopub.status.idle": "2024-01-03T14:16:17.407276Z",
          "shell.execute_reply.started": "2024-01-03T14:16:17.18969Z",
          "shell.execute_reply": "2024-01-03T14:16:17.406456Z"
        },
        "trusted": true,
        "id": "zJwULVFprmXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "\n",
        "t = 0\n",
        "a = 2\n",
        "b = 1\n",
        "vars()['trust_task'] = [[],[],[],[],[]]\n",
        "vars()['trust_ascend_task'] = [[],[],[],[],[]]\n",
        "for k in range(10):\n",
        "    k +=  1\n",
        "    t += (10 - k)\n",
        "\n",
        "for f in range(len(reliable)):\n",
        "    for i in range(len(vars()['reliable_trust_'+str(f)])):\n",
        "        trust_score = 0\n",
        "        init_trust = 0.5\n",
        "        trust_ascend = 0\n",
        "        t_cache = []\n",
        "        trust_ascend_data_t = []\n",
        "        for j in range(20):\n",
        "            if j % 2 == 0:\n",
        "                p = (j / 2 ) / t\n",
        "#                 print(p)\n",
        "                if (0 < vars()['reliable_trust_'+str(f)][task[f]+str(j+1)][i]) and (0 < vars()['reliable_trust_'+str(f)][task[f]+str(j+2)][i]):\n",
        "                    init_trust +=  (b - init_trust) / a\n",
        "                else:\n",
        "                    trust_score += 1\n",
        "                    init_trust -= (b * init_trust) / a\n",
        "                t_cache.append(init_trust * p)\n",
        "                trust_ascend += init_trust * p\n",
        "                trust_ascend_data_ =  vars()['reliable_trust_'+str(f)]['Worker'][i],'t'+str(int(j/2+1)),trust_ascend\n",
        "                trust_ascend_data_t.append(trust_ascend_data_)\n",
        "        trust_ascend_task[f].append(trust_ascend_data_t)\n",
        "\n",
        "        trust_data_ = vars()['reliable_trust_'+str(f)]['Worker'][i],sum(t_cache)\n",
        "        trust_task[f].append(trust_data_)\n",
        "    trus_ascend_modify = []\n",
        "    for m in range(len(trust_ascend_task[f])):\n",
        "        work_tust_ascend = pd.DataFrame(trust_ascend_task[f][m]) #worker1\n",
        "        work_tust_ascend.columns = ['Worker','Cycle','Current_trust']\n",
        "        trus_ascend_modify.append(work_tust_ascend)\n",
        "    vars()['trust_all_'+str(f)]= reduce(lambda left,right: pd.merge(left,right,how='outer',on=\"Cycle\"), trus_ascend_modify)\n",
        "    pd.set_option('display.max_columns',100)\n",
        "    pd.set_option('display.max_rows',20)\n",
        "execution_time = end_time - start_time\n",
        "print(\"程序执行时间：\", execution_time, \"秒\")\n",
        "trust_all_0 #TMEP relability  #t1 = 2 location data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:17.408716Z",
          "iopub.execute_input": "2024-01-03T14:16:17.408965Z",
          "iopub.status.idle": "2024-01-03T14:16:19.58262Z",
          "shell.execute_reply.started": "2024-01-03T14:16:17.408931Z",
          "shell.execute_reply": "2024-01-03T14:16:19.58161Z"
        },
        "trusted": true,
        "id": "S0yLqXCyrmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Discover \"TPA\""
      ],
      "metadata": {
        "id": "gV1bzDrZrmXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "pd.set_option('display.max_rows',200)\n",
        "pd.set_option('display.max_columns',100)\n",
        "threshold_TPA = 0.9\n",
        "for i in range(len(vars()['reliable'])):\n",
        "    trust_all = pd.DataFrame(trust_task[i])\n",
        "    trust_all.columns = ['Worker','Trust']\n",
        "    trust_all.insert(0,'Task',task[i])\n",
        "\n",
        "#     print(trust_all['Trust'])\n",
        "    vars()['TPA_'+str(i)] = trust_all[trust_all['Trust'] >= threshold_TPA].reset_index()\n",
        "    vars()['UNK_'+str(i)]  = trust_all[trust_all['Trust'] < threshold_TPA].reset_index()\n",
        "# unlabelled_worker.sort_values('Data_trust',ascending=True).reset_index()\n",
        "# spammer.sort_values('Data_trust',ascending=True).reset_index()\n",
        "T = TPA_0.merge(TPA_1.merge(TPA_2.merge(TPA_3.merge(TPA_4,how=\"outer\",on=\"Worker\"),how=\"outer\",on=\"Worker\"),\n",
        "                            how=\"outer\",on=\"Worker\"),how=\"outer\",on=\"Worker\")\n",
        "TPA = T.filter(regex='Worker|Task|Trust').reset_index()\n",
        "TPA\n",
        "#R^{threshold} 首先我们已经计算出了所有工人在任务中可靠度R，R的最高值为1，越接近1表明，工人具有在任务中的可靠度越高\n",
        "#因此，那些等于1的可靠度的工人，我们将其归类为TPAs,也就是阈值R^{threshold}=1。\n",
        "#但实际环境中，可能存在所有的工人的可靠度R都无法达到1。\n",
        "#为了应对这种情况，我们对R^{threshold}设置一个其他值 使其靠近1的状态，具体的计算可根据数据可视化、专家决策，排序法等选择最优的阈值，例如0.9等。排序取出前10然后均值、\n",
        "#若工人在参与的所有的任务中的可靠度R小于R^{threshold}，并且在每个任务中的可靠度R大于0.5，也就是表明他们有完成所有的任务50%的概率，我们将其归类为ARs。\n",
        "#对于剩余部分的工人，可根据实际情况重新检测或判定为spammer.\n",
        "#在我们的实验中，我们根据数据观察，发现工人在相关任务的最高可靠度R是0.989008，有14个工人具有这样的可靠度，且满足任务分配需要，因此我们就设置R^{threshold}>=0.989008."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.584067Z",
          "iopub.execute_input": "2024-01-03T14:16:19.584302Z",
          "iopub.status.idle": "2024-01-03T14:16:19.639553Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.584271Z",
          "shell.execute_reply": "2024-01-03T14:16:19.638546Z"
        },
        "trusted": true,
        "id": "7S6LbsThrmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Discover \"AT\""
      ],
      "metadata": {
        "id": "Lx-XOd3SrmXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_rows',10)\n",
        "# pd.set_option('display.max_columns',10)\n",
        "# vars()['UN_fit'] = [OW_TEMP.drop(['Label'],axis=1),OW_HUM.drop(['Label'],axis=1),\n",
        "#                     OW_CLD.drop(['Label'],axis=1),OW_WSD.drop(['Label'],axis=1),\n",
        "#                     OW_SR.drop(['Label'],axis=1)]\n",
        "# UNK = []\n",
        "# for i in range(len(vars()['UN_fit'])):\n",
        "#     UNK.append(UN_fit[i])\n",
        "# UNK_all = reduce(lambda left,right: pd.merge(left,right,how='outer',on=\"Worker\"),UNK)\n",
        "# UNK_data = pd.concat([UNK_all.filter(regex='Worker'), T.filter(regex='Worker')]).drop_duplicates(keep=False).reset_index()\n",
        "# UNK_data.merge(UNK_all,how='left',on=\"Worker\")\n",
        "threshold_AT = 0.6\n",
        "T = UNK_0.merge(UNK_1.merge(UNK_2.merge(UNK_3.merge(UNK_4,how=\"outer\",on=\"Worker\"),how=\"outer\",on=\"Worker\"),\n",
        "                            how=\"outer\",on=\"Worker\"),how=\"outer\",on=\"Worker\")\n",
        "UNK = T.filter(regex='Worker|Task|Trust')\n",
        "UNK_all = UNK[~UNK['Worker'].isin(TPA['Worker'])].filter(regex='Worker|Trust').reset_index().fillna(0)   #每个task  50%正确率。为全能型人才  根据信任度反推  个数。。。。。\n",
        "UNK_all['T'] = UNK_all.iloc[:,2:].sum(axis=1) / 5\n",
        "AT = UNK_all[UNK_all['T'] >= threshold_AT]\n",
        "AT.columns = ['Index','Worker','TEMP_T','HUM_T','Cloud_T','Wind-speed_T','SR_T','C_T']\n",
        "AT.reset_index()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.642112Z",
          "iopub.execute_input": "2024-01-03T14:16:19.642327Z",
          "iopub.status.idle": "2024-01-03T14:16:19.690393Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.642299Z",
          "shell.execute_reply": "2024-01-03T14:16:19.689635Z"
        },
        "trusted": true,
        "id": "43i4tzyPrmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Discovery \"UNK\""
      ],
      "metadata": {
        "id": "XO8a-CSMrmXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_UNK = 0.1\n",
        "UNK_all[(UNK_all['T'] < threshold_AT) & (UNK_all['T'] >= threshold_UNK)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.691369Z",
          "iopub.execute_input": "2024-01-03T14:16:19.691631Z",
          "iopub.status.idle": "2024-01-03T14:16:19.716912Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.6916Z",
          "shell.execute_reply": "2024-01-03T14:16:19.715916Z"
        },
        "trusted": true,
        "id": "spuPldFMrmXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Discovery \"Spammer\""
      ],
      "metadata": {
        "id": "kBhoEgNYrmXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_all[UNK_all['T'] < threshold_UNK] #There need to add the worker whose T is 0 ...."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.718018Z",
          "iopub.execute_input": "2024-01-03T14:16:19.718393Z",
          "iopub.status.idle": "2024-01-03T14:16:19.735973Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.718366Z",
          "shell.execute_reply": "2024-01-03T14:16:19.734867Z"
        },
        "trusted": true,
        "id": "wdcFfKb5rmXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Evaluate Data Bias of Our Schema"
      ],
      "metadata": {
        "id": "V0Am8jTArmXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A = OW_HUM[OW_HUM['Worker'].isin(TPA_1['Worker'])].filter(regex='Hum').reset_index().drop('index',axis=1)\n",
        "# B = GD_HUM.loc[:5,].filter(regex='Hum')\n",
        "# abs(B - A) / B\n",
        "\n",
        "D = []\n",
        "E_all = [ pd.DataFrame({'Bias_TEMP':[0]}) ,pd.DataFrame({'Bias_Humidity':[0]}) ,pd.DataFrame({'Bias_cloud':[0]}) ,\n",
        "         pd.DataFrame({'Bias_Wind-speed':[0]}),pd.DataFrame({'Bias_SR':[0]})]\n",
        "for i in range(5):\n",
        "    A = OW[i][OW[i]['Worker'].isin(vars()['TPA_'+str(i)]['Worker'])].filter(regex=task[i]).reset_index().drop('index',axis=1)\n",
        "    B = GT_fit[i].loc[:5,].filter(regex=task[i])\n",
        "    E = (abs(B - A) / B)\n",
        "    for j in range(20):\n",
        "        if j % 2 == 0:\n",
        "#             E_all[i].index = j/2+1\n",
        "            E_all[i].loc[j] = (np.sum(E[task[i]+str(j+1)]) + np.sum(E[task[i]+str(j+2)])) / (len(E.dropna()) * 2)\n",
        "#             print(int(j/2+1),np.sum(E[task[i]+str(j+1)]) + np.sum(E[task[i]+str(j+2)]))\n",
        "#             E_.append(task[i]+str(j+1),np.sum(E[task[i]+str(j+1)]) + np.sum(E[task[i]+str(j+2)]))\n",
        "    D.append((abs(B - A) / B))\n",
        "\n",
        "E_0 = E_all[0].reset_index().drop('index',axis=1)\n",
        "E_0.index = E_0.index + 1\n",
        "E_1 = E_all[1].reset_index().drop('index',axis=1)\n",
        "E_1.index = E_1.index + 1\n",
        "E_1.T\n",
        "E_2 = E_all[2].reset_index().drop('index',axis=1)\n",
        "E_2.index = E_2.index + 1\n",
        "E_2.T\n",
        "E_3 = E_all[3].reset_index().drop('index',axis=1)\n",
        "E_3.index = E_3.index + 1\n",
        "E_3.T\n",
        "E_4 = E_all[4].reset_index().drop('index',axis=1)\n",
        "E_4.index = E_4.index + 1\n",
        "E = E_0.T.append(E_1.T.append(E_2.T.append(E_3.T.append(E_4.T))))\n",
        "E.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "E.T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.737098Z",
          "iopub.execute_input": "2024-01-03T14:16:19.737278Z",
          "iopub.status.idle": "2024-01-03T14:16:19.908043Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.737254Z",
          "shell.execute_reply": "2024-01-03T14:16:19.907165Z"
        },
        "trusted": true,
        "id": "Kg_Lv_kzrmXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Mean method"
      ],
      "metadata": {
        "id": "ZaWO07mMrmXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "def mean_truth_bias(gt_data,data,Task):\n",
        "    bias_avg = 0\n",
        "    data = data.filter(regex=Task)\n",
        "    mean_truth_bias = pd.DataFrame({'Bias_'+Task:[0]})\n",
        "    E = abs(gt_data - data.mean()) / gt_data\n",
        "    for j in range(20):\n",
        "        if j % 2 == 0:\n",
        "            mean_truth_bias.loc[j] = (np.sum(E[Task+str(j+1)]) + np.sum(E[Task+str(j+2)])) / (len(E.dropna()) * 2)\n",
        "    mean_truth_bias = mean_truth_bias.reset_index().drop('index',axis=1)\n",
        "    mean_truth_bias.index = mean_truth_bias.index + 1\n",
        "    mean_truth_bias = mean_truth_bias.T\n",
        "    mean_truth_bias.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return mean_truth_bias\n",
        "mean_execution_time = (end_time - start_time) * 1000\n",
        "print(\"程序执行时间：\", mean_execution_time, \"毫秒\")\n",
        "\n",
        "mean_truth_bias(GT_fit[0],OW[0],'TEMP').append(mean_truth_bias(GT_fit[1],OW[1],'Humidity')\n",
        "                                               .append(mean_truth_bias(GT_fit[2],OW[2],'Cloud')\n",
        "                                                       .append(mean_truth_bias(GT_fit[3],OW[3],'Wind-speed')\n",
        "                                                               .append(mean_truth_bias(GT_fit[4],OW[4],'SR'))))).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:19.909Z",
          "iopub.execute_input": "2024-01-03T14:16:19.909183Z",
          "iopub.status.idle": "2024-01-03T14:16:20.06695Z",
          "shell.execute_reply.started": "2024-01-03T14:16:19.909157Z",
          "shell.execute_reply": "2024-01-03T14:16:20.066207Z"
        },
        "trusted": true,
        "id": "mPb35a85rmX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_truth_accuracy(data,Task,subsize):\n",
        "    mean_truth_accuracy = pd.DataFrame({'accuracy_'+Task:[0],'f1-score_'+Task:[0]})\n",
        "    unknow_data = data.filter(regex=Task)\n",
        "    bias = 2\n",
        "    for i in range(20):\n",
        "        if i % 2 == 0:\n",
        "            unknow_data['mean_label'+str(int(i/2+1))]  = 0\n",
        "            for j in range(len(data)):\n",
        "                if (abs(unknow_data[Task+str(i+1)][j] - unknow_data[Task+str(i+1)].mean()) <= bias) and (abs(unknow_data[Task+str(i+2)][j] - unknow_data[Task+str(i+2)].mean()) <= bias):\n",
        "                    unknow_data['mean_label'+str(int(i/2+1))][j] = 1\n",
        "                else:\n",
        "                    unknow_data['mean_label'+str(int(i/2+1))][j] = -1\n",
        "    pred = unknow_data.filter(regex='mean')\n",
        "\n",
        "    for t in range(10):\n",
        "        y_pre = np.array(pred['mean_label'+str(t+1)]).reshape(-1).astype(int)\n",
        "        mean_truth_accuracy.loc[t] = [accuracy_score(data['Label'],y_pre),f1_score(data['Label'],y_pre)]\n",
        "    if Task == 'Humidity':Task = 'HUM'\n",
        "    if Task == 'Cloud':Task = 'CLD'\n",
        "    if Task == 'Wind-speed':Task = 'WSD'\n",
        "    plot_roc(Task,data['Label'], y_pre,subsize)\n",
        "    plt.savefig('3.svg',dpi=600,bbox_inches = 'tight')\n",
        "    mean_truth_accuracy.index = mean_truth_accuracy.index + 1\n",
        "    mean_truth_accuracy = mean_truth_accuracy.T\n",
        "    mean_truth_accuracy.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return mean_truth_accuracy\n",
        "plt.figure(figsize = (30,4))\n",
        "\n",
        "mean_truth_accuracy(OW[0].loc[0:19],'TEMP',1).append(\n",
        "    mean_truth_accuracy(OW[1].loc[0:19],'Humidity',1)).append(\n",
        "    mean_truth_accuracy(OW[2].loc[0:19],'Cloud',1)).append(\n",
        "    mean_truth_accuracy(OW[3].loc[0:19],'Wind-speed',1)).append(\n",
        "    mean_truth_accuracy(OW[4].loc[0:19],'SR',1)).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:20.06804Z",
          "iopub.execute_input": "2024-01-03T14:16:20.068254Z",
          "iopub.status.idle": "2024-01-03T14:16:21.575841Z",
          "shell.execute_reply.started": "2024-01-03T14:16:20.068207Z",
          "shell.execute_reply": "2024-01-03T14:16:21.575121Z"
        },
        "trusted": true,
        "id": "48oaJYbSrmX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. MV method"
      ],
      "metadata": {
        "id": "fUTrkleSrmX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "\n",
        "def mv_truth_bias(gt_data,data,Task):\n",
        "    bias_avg = 0\n",
        "    data = data.filter(regex=Task)\n",
        "    mv_truth_bias = pd.DataFrame({'Bias_'+Task:[0]})\n",
        "    E = abs(gt_data - data.round().mode()) / gt_data\n",
        "    for j in range(20):\n",
        "        if j % 2 == 0:\n",
        "            mv_truth_bias.loc[j] = (np.sum(E[Task+str(j+1)]) + np.sum(E[Task+str(j+2)])) / (len(E.dropna()) * 2)\n",
        "    mv_truth_bias = mv_truth_bias.reset_index().drop('index',axis=1)\n",
        "    mv_truth_bias.index = mv_truth_bias.index + 1\n",
        "    mv_truth_bias = mv_truth_bias.T\n",
        "    mv_truth_bias.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return mv_truth_bias\n",
        "mv_execution_time = (end_time - start_time) * 1000\n",
        "print(\"程序执行时间：\", mv_execution_time, \"毫秒\")\n",
        "\n",
        "mv_truth_bias(GT_fit[0],OW[0],'TEMP').append(mv_truth_bias(GT_fit[1],OW[1],'Humidity')\n",
        "                                               .append(mv_truth_bias(GT_fit[2],OW[2],'Cloud')\n",
        "                                                       .append(mv_truth_bias(GT_fit[3],OW[3],'Wind-speed')\n",
        "                                                               .append(mv_truth_bias(GT_fit[4],OW[4],'SR'))))).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:21.577046Z",
          "iopub.execute_input": "2024-01-03T14:16:21.577248Z",
          "iopub.status.idle": "2024-01-03T14:16:21.792322Z",
          "shell.execute_reply.started": "2024-01-03T14:16:21.577221Z",
          "shell.execute_reply": "2024-01-03T14:16:21.791573Z"
        },
        "trusted": true,
        "id": "qH7BDkJprmX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mv_truth_accuracy(data,Task,subsize):\n",
        "    mv_truth_accuracy = pd.DataFrame({'accuracy_'+Task:[0],'f1-score_'+Task:[0]})\n",
        "    unknow_data = data.filter(regex=Task)\n",
        "    bias = 2\n",
        "    for i in range(20):\n",
        "        if i % 2 == 0:\n",
        "            unknow_data['mv_label'+str(int(i/2+1))]  = 0\n",
        "            for j in range(len(data)):\n",
        "                if (abs(unknow_data[Task+str(i+1)][j] - unknow_data[Task+str(i+1)].round().mode()[0]) <= bias) and (\n",
        "                    abs(unknow_data[Task+str(i+2)][j] - unknow_data[Task+str(i+2)].round().mode()[0]) <= bias):\n",
        "                    unknow_data['mv_label'+str(int(i/2+1))][j] = 1\n",
        "                else:\n",
        "                    unknow_data['mv_label'+str(int(i/2+1))][j] = -1\n",
        "    pred = unknow_data.filter(regex='mv')\n",
        "\n",
        "    for t in range(10):\n",
        "        y_pre = np.array(pred['mv_label'+str(t+1)]).reshape(-1).astype(int)\n",
        "        mv_truth_accuracy.loc[t] = [accuracy_score(data['Label'],y_pre),f1_score(data['Label'],y_pre)]\n",
        "    if Task == 'Humidity':Task = 'HUM'\n",
        "    if Task == 'Cloud':Task = 'CLD'\n",
        "    if Task == 'Wind-speed':Task = 'WSD'\n",
        "    plot_roc(Task,data['Label'], y_pre,subsize,'upper left')# The last time-step\n",
        "    plt.savefig('4.svg',dpi=600,bbox_inches = 'tight')\n",
        "    mv_truth_accuracy.index = mv_truth_accuracy.index + 1\n",
        "    mv_truth_accuracy = mv_truth_accuracy.T\n",
        "    mv_truth_accuracy.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return mv_truth_accuracy\n",
        "plt.figure(figsize = (30,4))\n",
        "\n",
        "mv_truth_accuracy(OW[0].loc[0:19],'TEMP',1).append(mv_truth_accuracy(OW[1].loc[0:19],'Humidity',1)).append(\n",
        "    mv_truth_accuracy(OW[2].loc[0:19],'Cloud',1)).append(mv_truth_accuracy(OW[3].loc[0:19],'Wind-speed',1)).append(\n",
        "    mv_truth_accuracy(OW[4].loc[0:19],'SR',1)).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:21.793265Z",
          "iopub.execute_input": "2024-01-03T14:16:21.793442Z",
          "iopub.status.idle": "2024-01-03T14:16:23.419383Z",
          "shell.execute_reply.started": "2024-01-03T14:16:21.793417Z",
          "shell.execute_reply": "2024-01-03T14:16:23.418456Z"
        },
        "trusted": true,
        "id": "NHH8QrtQrmX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Median method"
      ],
      "metadata": {
        "id": "03vJ2IaxrmX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def median_truth_bias(gt_data,data,Task):\n",
        "    bias_avg = 0\n",
        "    data = data.filter(regex=Task)\n",
        "    median_truth_bias = pd.DataFrame({'Bias_'+Task:[0]})\n",
        "    E = abs(data - data.round().median()) / gt_data\n",
        "\n",
        "    for j in range(20):\n",
        "        if j % 2 == 0:\n",
        "            median_truth_bias.loc[j] = (np.sum(E[Task+str(j+1)]) + np.sum(E[Task+str(j+2)])) / (len(E.dropna()) * 2)\n",
        "    median_truth_bias = median_truth_bias.reset_index().drop('index',axis=1)\n",
        "    median_truth_bias.index = median_truth_bias.index + 1\n",
        "    median_truth_bias = median_truth_bias.T\n",
        "    median_truth_bias.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return median_truth_bias\n",
        "\n",
        "median_truth_bias(GT_fit[0],OW[0],'TEMP').append(median_truth_bias(GT_fit[1],OW[1],'Humidity')\n",
        "                                               .append(median_truth_bias(GT_fit[2],OW[2],'Cloud')\n",
        "                                                       .append(median_truth_bias(GT_fit[3],OW[3],'Wind-speed')\n",
        "                                                               .append(median_truth_bias(GT_fit[4],OW[4],'SR')))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:23.420504Z",
          "iopub.execute_input": "2024-01-03T14:16:23.420712Z",
          "iopub.status.idle": "2024-01-03T14:16:23.597606Z",
          "shell.execute_reply.started": "2024-01-03T14:16:23.420686Z",
          "shell.execute_reply": "2024-01-03T14:16:23.597043Z"
        },
        "trusted": true,
        "id": "HNWUyzIdrmX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def median_truth_accuracy(data,Task,subsize):\n",
        "    median_truth_accuracy = pd.DataFrame({'accuracy_'+Task:[0],'f1-score_'+Task:[0]})\n",
        "    unknow_data = data.filter(regex=Task)\n",
        "    bias = 2\n",
        "    for i in range(20):\n",
        "        if i % 2 == 0:\n",
        "            unknow_data['mv_label'+str(int(i/2+1))]  = 0\n",
        "            for j in range(len(data)):\n",
        "                if (abs(unknow_data[Task+str(i+1)][j] - unknow_data[Task+str(i+1)].round().median()) <= bias) and (\n",
        "                    abs(unknow_data[Task+str(i+2)][j] - unknow_data[Task+str(i+2)].round().median()) <= bias):\n",
        "                    unknow_data['mv_label'+str(int(i/2+1))][j] = 1\n",
        "                else:\n",
        "                    unknow_data['mv_label'+str(int(i/2+1))][j] = -1\n",
        "    pred = unknow_data.filter(regex='mv')\n",
        "\n",
        "    for t in range(10):\n",
        "        y_pre = np.array(pred['mv_label'+str(t+1)]).reshape(-1).astype(int)\n",
        "        median_truth_accuracy.loc[t] = [accuracy_score(data['Label'],y_pre),f1_score(data['Label'],y_pre)]\n",
        "    if Task == 'Humidity':Task = 'HUM'\n",
        "    if Task == 'Cloud':Task = 'CLD'\n",
        "    if Task == 'Wind-speed':Task = 'WSD'\n",
        "    plot_roc(Task,data['Label'], y_pre,subsize,'upper left')# The last time-step\n",
        "    plt.savefig('5.svg',dpi=600,bbox_inches = 'tight')\n",
        "    median_truth_accuracy.index = median_truth_accuracy.index + 1\n",
        "    median_truth_accuracy = median_truth_accuracy.T\n",
        "    median_truth_accuracy.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return median_truth_accuracy\n",
        "plt.figure(figsize = (30,4))\n",
        "\n",
        "median_truth_accuracy(OW[0].loc[0:19],'TEMP',1).append(median_truth_accuracy(OW[1].loc[0:19],'Humidity',1)).append(\n",
        "    median_truth_accuracy(OW[2].loc[0:19],'Cloud',1)).append(median_truth_accuracy(OW[3].loc[0:19],'Wind-speed',1)).append(\n",
        "    median_truth_accuracy(OW[4].loc[0:19],'SR',1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:23.598662Z",
          "iopub.execute_input": "2024-01-03T14:16:23.598846Z",
          "iopub.status.idle": "2024-01-03T14:16:25.373055Z",
          "shell.execute_reply.started": "2024-01-03T14:16:23.59882Z",
          "shell.execute_reply": "2024-01-03T14:16:25.372004Z"
        },
        "trusted": true,
        "id": "0K9FT3MQrmX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. GD method"
      ],
      "metadata": {
        "id": "z5GyBSb-rmX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "end_time = time.time()\n",
        "\n",
        "A = TPA_TEMP[TPA_TEMP['Label'] == 1]\n",
        "B = OW_HUM[OW_HUM['Worker'].isin(A['Worker'])]\n",
        "C = OW_CLD[OW_CLD['Worker'].isin(A['Worker'])]\n",
        "D = OW_WSD[OW_WSD['Worker'].isin(A['Worker'])]\n",
        "E = OW_SR[OW_SR['Worker'].isin(A['Worker'])]\n",
        "\n",
        "def gd_truth_bias(gt_data,data,Task):\n",
        "    bias_avg = 0\n",
        "    data = data.filter(regex=Task)\n",
        "    gd_truth_bias = pd.DataFrame({'Bias_'+Task:[0]})\n",
        "    E = abs(gt_data - data) / gt_data\n",
        "    for j in range(20):\n",
        "        if j % 2 == 0:\n",
        "            gd_truth_bias.loc[j] = (np.sum(E[Task+str(j+1)]) + np.sum(E[Task+str(j+2)])) / (len(E.dropna()) * 2)\n",
        "    gd_truth_bias = gd_truth_bias.reset_index().drop('index',axis=1)\n",
        "    gd_truth_bias.index = gd_truth_bias.index + 1\n",
        "    gd_truth_bias = gd_truth_bias.T\n",
        "    gd_truth_bias.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return gd_truth_bias\n",
        "gd_execution_time = (end_time - start_time) * 1000\n",
        "print(\"程序执行时间：\", gd_execution_time, \"毫秒\")\n",
        "\n",
        "gd_truth_bias(GT_fit[0],A,'TEMP').append(gd_truth_bias(GT_fit[1],B,'Humidity')\n",
        "                                               .append(gd_truth_bias(GT_fit[2],C,'Cloud')\n",
        "                                                       .append(gd_truth_bias(GT_fit[3],D,'Wind-speed')\n",
        "                                                               .append(gd_truth_bias(GT_fit[4],E,'SR'))))).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:25.37409Z",
          "iopub.execute_input": "2024-01-03T14:16:25.3743Z",
          "iopub.status.idle": "2024-01-03T14:16:25.535086Z",
          "shell.execute_reply.started": "2024-01-03T14:16:25.374272Z",
          "shell.execute_reply": "2024-01-03T14:16:25.53414Z"
        },
        "trusted": true,
        "id": "MPeeT9SXrmX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reliable_TEMP = OW_TEMP[OW_TEMP['Worker'].isin(A['Worker'])]\n",
        "reliable_TEMP['Label'] = 1\n",
        "unreliable_TEMP = OW_TEMP[~OW_TEMP['Worker'].isin(A['Worker'])]\n",
        "unreliable_TEMP['Label'] = -1\n",
        "UNK_TEMP = reliable_TEMP.append(unreliable_TEMP).sort_index()\n",
        "\n",
        "reliable_HUM = OW_HUM[OW_HUM['Worker'].isin(A['Worker'])]\n",
        "reliable_HUM['Label'] = 1\n",
        "unreliable_HUM = OW_HUM[~OW_HUM['Worker'].isin(A['Worker'])]\n",
        "unreliable_HUM['Label'] = -1\n",
        "UNK_HUM = reliable_HUM.append(unreliable_HUM).sort_index()\n",
        "\n",
        "reliable_CLD = OW_CLD[OW_CLD['Worker'].isin(A['Worker'])]\n",
        "reliable_CLD['Label'] = 1\n",
        "unreliable_CLD = OW_CLD[~OW_CLD['Worker'].isin(A['Worker'])]\n",
        "unreliable_CLD['Label'] = -1\n",
        "UNK_CLD = reliable_CLD.append(unreliable_CLD).sort_index()\n",
        "\n",
        "reliable_WSD = OW_WSD[OW_WSD['Worker'].isin(A['Worker'])]\n",
        "reliable_WSD['Label'] = 1\n",
        "unreliable_WSD = OW_WSD[~OW_WSD['Worker'].isin(A['Worker'])]\n",
        "unreliable_WSD['Label'] = -1\n",
        "UNK_WSD = reliable_WSD.append(unreliable_WSD).sort_index()\n",
        "\n",
        "reliable_SR = OW_SR[OW_SR['Worker'].isin(A['Worker'])]\n",
        "reliable_SR['Label'] = 1\n",
        "unreliable_SR = OW_SR[~OW_SR['Worker'].isin(A['Worker'])]\n",
        "unreliable_SR['Label'] = -1\n",
        "UNK_SR = reliable_SR.append(unreliable_SR).sort_index()\n",
        "\n",
        "plt.figure(figsize = (30,4))\n",
        "plot_roc('TEMP',OW[0].loc[0:19,'Label'], UNK_TEMP[0:20]['Label'],1)\n",
        "plot_roc('HUM',OW[1].loc[0:19,'Label'], UNK_HUM[0:20]['Label'],1)\n",
        "plot_roc('CLD',OW[2].loc[0:19,'Label'], UNK_CLD[0:20]['Label'],1)\n",
        "plot_roc('WSD',OW[3].loc[0:19,'Label'], UNK_WSD[0:20]['Label'],1)\n",
        "plot_roc('SR',OW[4].loc[0:19,'Label'], UNK_SR[0:20]['Label'],1)\n",
        "plt.savefig('6.svg',dpi=600,bbox_inches = 'tight')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:25.536433Z",
          "iopub.execute_input": "2024-01-03T14:16:25.536634Z",
          "iopub.status.idle": "2024-01-03T14:16:25.874237Z",
          "shell.execute_reply.started": "2024-01-03T14:16:25.53661Z",
          "shell.execute_reply": "2024-01-03T14:16:25.873135Z"
        },
        "trusted": true,
        "id": "3y6tpq48rmX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gd_truth_accuracy(GT_data,UNK_data,Task):\n",
        "    gd_truth_accuracy = pd.DataFrame({'accuracy_'+Task:[0],'f1-score_'+Task:[0]})\n",
        "    unknow_data = UNK_data.filter(regex=Task)\n",
        "    for t in range(10):\n",
        "        gd_truth_accuracy.loc[t] = [accuracy_score(GT_data['Label'],UNK_data['Label']),f1_score(GT_data['Label'],UNK_data['Label'])]\n",
        "    gd_truth_accuracy.index = gd_truth_accuracy.index + 1\n",
        "    gd_truth_accuracy = gd_truth_accuracy.T\n",
        "    gd_truth_accuracy.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
        "    return gd_truth_accuracy\n",
        "gd_truth_accuracy(OW[0].loc[0:19],UNK_TEMP[0:20],'TEMP').append(gd_truth_accuracy(OW[1].loc[0:19],UNK_HUM[0:20],'Humidity')).append(\n",
        "    gd_truth_accuracy(OW[2].loc[0:19],UNK_CLD[0:20],'Cloud')).append(gd_truth_accuracy(OW[3].loc[0:19],UNK_WSD[0:20],'Wind-speed')).append(\n",
        "    gd_truth_accuracy(OW[4].loc[0:19],UNK_SR[0:20],'SR')).T"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:25.875883Z",
          "iopub.execute_input": "2024-01-03T14:16:25.876167Z",
          "iopub.status.idle": "2024-01-03T14:16:26.028392Z",
          "shell.execute_reply.started": "2024-01-03T14:16:25.876138Z",
          "shell.execute_reply": "2024-01-03T14:16:26.027916Z"
        },
        "trusted": true,
        "id": "TtStaVDHrmX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Not datasets testing"
      ],
      "metadata": {
        "id": "oKhjZTbjrmX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mean temp\n",
        "import numpy as np\n",
        "gd_data = np.array([\n",
        "[25.03,26.02,24.08,25.03,26.01],\n",
        "[25.01,25.98,24.05,25.21,25.85],\n",
        "[25.03,26.02,24.05,26.21,25.01],\n",
        "[25.01,25.98,24.08,25.25,25.28],\n",
        "[25.03,26.01,24.10,25.35,25.28]]\n",
        ")\n",
        "\n",
        "worker_report = np.array([\n",
        "[25.03,26.02,24.08,25.03,26.01],\n",
        "[27.88,28.32,26.7,28.83,30.21],\n",
        "[25.03,26.02,24.05,25.25,26.82],\n",
        "[27.98,28.98,26.78,28.85,30.26],\n",
        "[27.21,28.21,26.54,28.68,30.26]\n",
        "])\n",
        "\n",
        "list_data = []\n",
        "#mean\n",
        "for i in range(5):\n",
        "    list_data.append(abs(gd_data[:,i] - worker_report[:,i].mean()) / gd_data[:,i])\n",
        "for i in range(5):\n",
        "    print(sum(list_data[i]) )\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.029163Z",
          "iopub.execute_input": "2024-01-03T14:16:26.029904Z",
          "iopub.status.idle": "2024-01-03T14:16:26.038437Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.029877Z",
          "shell.execute_reply": "2024-01-03T14:16:26.037364Z"
        },
        "trusted": true,
        "id": "HMkaP5p1rmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MV temp\n",
        "list_data2 = []\n",
        "for i in range(5):\n",
        "    list_data2.append(abs(gd_data[:,i] - np.argmax(np.bincount(list(worker_report[:,i])))) / gd_data[:,i])\n",
        "for i in range(5):\n",
        "    print(sum(list_data2[i]))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.039721Z",
          "iopub.execute_input": "2024-01-03T14:16:26.039962Z",
          "iopub.status.idle": "2024-01-03T14:16:26.052438Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.039929Z",
          "shell.execute_reply": "2024-01-03T14:16:26.051626Z"
        },
        "trusted": true,
        "id": "-dC6OaxKrmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GD temp\n",
        "list_data3 = []\n",
        "b = np.isin(worker_report,gd_data)\n",
        "print(b)\n",
        "\n",
        "worker_report2 = np.array([\n",
        "[25.03,26.02,24.08,25.03,26.01],\n",
        "[25.01,25.98,24.05,25.21,25.85],\n",
        "[25.03,26.02,24.05,26.21,26.82],\n",
        "[25.01,25.98,24.08,25.25,25.28],\n",
        "[25.03,26.01,24.10,25.35,25.28]]\n",
        ")\n",
        "\n",
        "for i in range(5):\n",
        "    list_data3.append(abs(gd_data[:,i] - worker_report2[:,i])  / gd_data[:,i])\n",
        "for i in range(5):\n",
        "    print(sum(list_data3[i]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.054232Z",
          "iopub.execute_input": "2024-01-03T14:16:26.054536Z",
          "iopub.status.idle": "2024-01-03T14:16:26.065094Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.054504Z",
          "shell.execute_reply": "2024-01-03T14:16:26.06396Z"
        },
        "trusted": true,
        "id": "kvXrW0IarmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean water-level\n",
        "import numpy as np\n",
        "gd_data = np.array([\n",
        "[150.23,160.01,150.28,150.55,160.23],\n",
        "[150.13,159.23,151.30,149.89,161.08],\n",
        "[152.56,160.33,151.02,151.22,160.33],\n",
        "[150.33,159.53,151.73,150.78,159.45],\n",
        "[153.45,161.33,149.23,150.01,159.75],\n",
        "])\n",
        "\n",
        "\n",
        "worker_report = np.array([\n",
        "[155.23,165.01,155.28,155.55,165.23],\n",
        "[170.22,175.31,170.25,174.31,175.85],\n",
        "[171.13,160.33,151.02,151.22,160.33],\n",
        "[165.13,169.23,171.30,169.89,171.08],\n",
        "[150.23,159.53,151.02,149.89,159.45],\n",
        "]\n",
        ")\n",
        "\n",
        "\n",
        "list_data = []\n",
        "#mean\n",
        "for i in range(5):\n",
        "    list_data.append(abs(gd_data[:,i] - worker_report[:,i].mean()) / gd_data[:,i])\n",
        "for i in range(5):\n",
        "    print(sum(list_data[i]))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.06634Z",
          "iopub.execute_input": "2024-01-03T14:16:26.066647Z",
          "iopub.status.idle": "2024-01-03T14:16:26.080951Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.06662Z",
          "shell.execute_reply": "2024-01-03T14:16:26.079752Z"
        },
        "trusted": true,
        "id": "AkEESkKdrmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MV water-level\n",
        "list_data_water = []\n",
        "for i in range(5):\n",
        "    list_data_water.append(abs(gd_data[:,i] - np.argmax(np.bincount(list(worker_report[:,i])))) / gd_data[:,i])\n",
        "\n",
        "for i in range(5):\n",
        "    print(sum(list_data_water[i]) )\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.082166Z",
          "iopub.execute_input": "2024-01-03T14:16:26.082375Z",
          "iopub.status.idle": "2024-01-03T14:16:26.09217Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.082351Z",
          "shell.execute_reply": "2024-01-03T14:16:26.091262Z"
        },
        "trusted": true,
        "id": "bZskloUlrmX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GD water-level\n",
        "list_data3 = []\n",
        "worker_report2 = np.array([\n",
        "[155.23,165.01,155.28,155.55,165.23],\n",
        "[150.13,159.23,151.30,149.89,161.08],\n",
        "[171.13,160.33,151.02,151.22,160.33],\n",
        "[150.33,159.53,151.73,150.78,159.45],\n",
        "[150.23,159.53,151.02,149.89,159.45],\n",
        "]\n",
        ")\n",
        "for i in range(5):\n",
        "    list_data3.append(abs(gd_data[:,i] - worker_report2[:,i]) / gd_data[:,i] )\n",
        "for i in range(5):\n",
        "    print(sum(list_data3[i] ))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.094988Z",
          "iopub.execute_input": "2024-01-03T14:16:26.095202Z",
          "iopub.status.idle": "2024-01-03T14:16:26.105231Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.095176Z",
          "shell.execute_reply": "2024-01-03T14:16:26.104472Z"
        },
        "trusted": true,
        "id": "REO-6-gprmX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TPAAD water-level\n",
        "list_data3 = []\n",
        "worker_report2 = np.array([\n",
        "[150.23,160.01,150.28,150.55,160.23],\n",
        "[150.13,159.23,151.30,149.89,161.08],\n",
        "[171.13,160.33,151.02,151.22,160.33],\n",
        "[150.33,159.53,151.73,150.78,159.45],\n",
        "[150.23,159.53,151.02,149.89,159.45],\n",
        "]\n",
        ")\n",
        "for i in range(5):\n",
        "    list_data3.append(abs(gd_data[:,i] - worker_report2[:,i]) / gd_data[:,i] )\n",
        "for i in range(5):\n",
        "    print(sum(list_data3[i] ))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T14:16:26.106178Z",
          "iopub.execute_input": "2024-01-03T14:16:26.106341Z",
          "iopub.status.idle": "2024-01-03T14:16:26.117295Z",
          "shell.execute_reply.started": "2024-01-03T14:16:26.106319Z",
          "shell.execute_reply": "2024-01-03T14:16:26.116457Z"
        },
        "trusted": true,
        "id": "PokhxQsJrmX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}