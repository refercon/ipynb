{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp4G/vGEZEy87QCnVcbYeJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/refercon/ipynb/blob/main/Face_recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VVWs0aISpjo",
        "outputId": "fe525231-7511-4db9-d2ba-cf0713d689c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting mtcnn\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/09/d1/2a4269e387edb97484157b872fa8a1953b53dcafbe4842a1967f549ac5ea/mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.0/2.3 MB 660.6 kB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.1/2.3 MB 1.4 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 0.4/2.3 MB 2.9 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 0.7/2.3 MB 3.8 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 1.0/2.3 MB 4.6 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 1.9/2.3 MB 7.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.3/2.3 MB 7.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: keras>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from mtcnn) (2.6.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in d:\\anaconda3\\lib\\site-packages (from mtcnn) (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.17.0 in d:\\anaconda3\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (d:\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnRinCJEyK4a"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# from facenet_pytorch import MTCNN\n",
        "# import numpy as np\n",
        "# import time\n",
        "# import random\n",
        "\n",
        "# # 创建一个MTCNN实例\n",
        "# mtcnn = MTCNN()\n",
        "# # 打开摄像头\n",
        "# cap = cv2.VideoCapture(0)\n",
        "# # 初始化人脸计数器\n",
        "# face_count = 0\n",
        "\n",
        "# while face_count < 500:\n",
        "#     # 读取视频帧\n",
        "#     ret, frame = cap.read()\n",
        "#     # 使用MTCNN检测人脸\n",
        "#     boxes, _ = mtcnn.detect(frame)\n",
        "#     # 如果检测到人脸\n",
        "#     if boxes is not None:\n",
        "#         for box in boxes:\n",
        "#             # 提取人脸坐标\n",
        "#             x1, y1, x2, y2 = box.astype(int)\n",
        "#             # 提取人脸图像\n",
        "#             face = frame[y1:y2, x1:x2]\n",
        "#             # 数据增强：缩放\n",
        "#             face = cv2.resize(face, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
        "#             # 数据增强：随机旋转\n",
        "#             angle = random.randint(-30, 30)  # 随机选择旋转角度\n",
        "#             rows, cols = face.shape[:2]\n",
        "#             M = cv2.getRotationMatrix2D(((cols-1)/2.0, (rows-1)/2.0), angle, 1)\n",
        "#             face = cv2.warpAffine(face, M, (cols, rows))\n",
        "#             # 生成唯一的文件名\n",
        "#             filename = f\"E:/pic/1/face_{face_count}.png\"\n",
        "#             # 保存人脸图像\n",
        "#             cv2.imwrite(filename, face)\n",
        "#             # 在视频帧上画出人脸边框\n",
        "#             cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "#             # 更新人脸计数器\n",
        "#             face_count += 1\n",
        "\n",
        "#     # 显示带有人脸边框的视频帧\n",
        "#     cv2.imshow('Video', frame)\n",
        "\n",
        "#     # 按'q'键退出循环\n",
        "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# # 释放摄像头并关闭所有窗口\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for label in [1, 2]:\n",
        "            directory = os.path.join(root_dir, str(label))\n",
        "            for filename in os.listdir(directory):\n",
        "                if filename.endswith('.png'):\n",
        "                    self.images.append(os.path.join(directory, filename))\n",
        "                    self.labels.append(label - 1)  # labels: 0 or 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 数据转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 创建数据集\n",
        "dataset = FaceDataset(root_dir='E:/pic', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "    # print(labels)"
      ],
      "metadata": {
        "id": "RLwYcOnGyc2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # 只显示一批图像\n",
        "# images, labels = next(iter(dataloader))\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# for i in range(2):\n",
        "#     plt.subplot(1, 2, i + 1)\n",
        "#     plt.imshow(images[i].permute(1, 2, 0))  # 将通道顺序改为(H, W, C)以适应matplotlib\n",
        "#     plt.title(f\"Label: {labels[i]}\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "Hnl_TFbAgk94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # 根据新的特征图尺寸调整全连接层\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        # 删除conv3层\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = F.relu(self.fc1(self.dropout(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "flqGwcRi8PY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def calculate_accuracy_f1(model, dataloader, device):\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # 将数据转移到设备\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())  # 将标签移回CPU\n",
        "            pred_labels.extend(predicted.cpu().numpy())  # 将预测结果移回CPU\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "# 训练过程\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # 设置模型为训练模式\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # 将数据转移到设备\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 计算每个epoch的平均loss\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "\n",
        "    # 计算accuracy和f1-score\n",
        "    accuracy, f1 = calculate_accuracy_f1(model, dataloader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
        "# 保存训练好的模型\n",
        "torch.save(model.state_dict(), 'face_classification_model.pth')"
      ],
      "metadata": {
        "id": "w4Vyz1IeIdun",
        "outputId": "1d29bd8f-f1b9-4eb2-8099-058478cbd810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.4824, Accuracy: 0.9900, F1-Score: 0.9900\n",
            "Epoch 2/10, Loss: 0.0519, Accuracy: 0.9900, F1-Score: 0.9900\n",
            "Epoch 3/10, Loss: 0.0615, Accuracy: 0.9770, F1-Score: 0.9770\n",
            "Epoch 4/10, Loss: 0.0892, Accuracy: 0.9570, F1-Score: 0.9570\n",
            "Epoch 5/10, Loss: 0.0206, Accuracy: 0.9790, F1-Score: 0.9790\n",
            "Epoch 6/10, Loss: 0.0809, Accuracy: 0.9300, F1-Score: 0.9297\n",
            "Epoch 7/10, Loss: 0.0782, Accuracy: 0.9060, F1-Score: 0.9057\n",
            "Epoch 8/10, Loss: 0.1076, Accuracy: 0.9430, F1-Score: 0.9430\n",
            "Epoch 9/10, Loss: 0.0096, Accuracy: 0.8760, F1-Score: 0.8760\n",
            "Epoch 10/10, Loss: 0.0073, Accuracy: 0.9720, F1-Score: 0.9720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载模型\n",
        "model = SimpleCNN()\n",
        "model.load_state_dict(torch.load('face_classification_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# 定义转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open('E:\\\\pic\\\\2\\\\face_200.png')  # 请将'your_image.jpg'替换为你的图像文件名\n",
        "\n",
        "# 应用转换并添加批处理维度\n",
        "input = transform(img).unsqueeze(0)\n",
        "\n",
        "# 进行预测\n",
        "output = model(input)\n",
        "\n",
        "# 获取预测结果\n",
        "_, predicted = torch.max(output.data, 1)\n",
        "\n",
        "print('Predicted label:', predicted.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs_UqS1OVejg",
        "outputId": "5abb2cb3-82f4-48d4-ceb1-b13679c0a14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "# 加载模型\n",
        "model = SimpleCNN()\n",
        "model.load_state_dict(torch.load('face_classification_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# 定义转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "# 定义标签列表\n",
        "labels = ['YC', 'WW']  # 请根据你的模型替换这些标签\n",
        "# 创建MTCNN模型\n",
        "mtcnn = MTCNN()\n",
        "\n",
        "# 打开摄像头\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "confidence_threshold = 0.9  # 置信度阈值\n",
        "\n",
        "while True:\n",
        "    # 读取帧\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 使用MTCNN进行人脸检测\n",
        "    boxes, probs = mtcnn.detect(frame)\n",
        "\n",
        "    # 如果检测到人脸\n",
        "    if boxes is not None:\n",
        "        for box, prob in zip(boxes, probs):\n",
        "            # 检查置信度\n",
        "\n",
        "                # 提取人脸\n",
        "            face = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
        "                # 转换帧为图像\n",
        "            img = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            # 应用转换并添加批处理维度\n",
        "            input_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "            # 进行预测\n",
        "            output = model(input_tensor)\n",
        "\n",
        "                # 获取预测结果\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "                # 获取预测标签\n",
        "            label = labels[predicted.item()] if predicted.item() < len(labels) else 'Unknown'\n",
        "\n",
        "            # 在帧上添加预测标签\n",
        "            cv2.putText(frame, label, (int(box[0]), int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # 在帧上画出人脸的边界框\n",
        "            cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "\n",
        "    # 显示帧\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    # 按'q'键退出\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# 释放摄像头并关闭窗口\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "iV2E_usdQsD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37979761-df1e-4500-fda6-e249c2cc4fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "d:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        }
      ]
    }
  ]
}